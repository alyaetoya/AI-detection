## AI-detection для текстов на русском языке
_Автор проекта: студентка БКЛ221 Алевтина Широкова_

В этом проекте рассматривается задача определения текстов, сгенерированных искусственным интеллектом, на материале русского языка. Проще говоря, цель работы — научиться автоматически отличать тексты, написанные человеком, от текстов, созданных языковыми моделями. Эта задача становится всё более актуальной по мере развития генеративных моделей, тексты которых всё сложнее отличить от человеческих.
Проект задуман как сравнительное исследование различных NLP-подходов: от классических моделей машинного обучения до трансформеров и современных больших языковых моделей.

В качестве основного источника данных используется датасет CoAT (binary) — открытый русскоязычный датасет для задачи AI-detection, изначально созданный в рамках соревнования по определению AI-сгенерированных текстов. Это делает его исключительно подходящим для поставленных мной исследовательских целей. Датасет содержит тексты двух типов: написанные человеком и сгенерированные ИИ. Тексты человеческого авторства собраны на базе НКРЯ, социальных сетей, Википедии и оцифрованных личных дневников. Тексты, написанные ИИ, собраны на основе выдачи 13 генерирующих моделей, имеющих в инпукте человеческий текст и настроенных для одной или нескольких задач генерации естественного языка: машинный перевод, генерация перефразирования, упрощение текста и обобщение текста.
Датасет содержит тексты двух типов: написанные человеком и сгенерированные ИИ. Используется бинарная разметка: метка 0 соответствует человеческим текстам, а метка 1 — AI-сгенерированным. Обучающая выборка включает более 170 тысяч примеров, что позволяет обучать модели разной сложности. Для оценки качества используется валидационная выборка. Тестовая часть датасета не применяется, поскольку в ней скрыты истинные метки классов (все значения равны -1), а значит корректная количественная оценка невозможна.

В работе рассматриваются несколько подходов с постепенно возрастающей сложностью. В качестве отправной точки используется классический baseline — TF-IDF-векторизация в сочетании с логистической регрессией. Эта модель опирается на частотные и лексические признаки текста, работает быстро и легко интерпретируется. Несмотря на свою простоту, baseline показывает вполне достойные результаты, что говорит о том, что AI-сгенерированные тексты действительно обладают определёнными поверхностными паттернами, которые можно уловить даже без глубокого понимания контекста. Более сложный и мощный подход основан на дообучении трансформерной модели RuBERT для задачи бинарной классификации текстов. RuBERT предварительно обучен на русскоязычных корпусах, что делает его особенно подходящим для работы с русским языком. Fine-tuning позволяет адаптировать модель под конкретную задачу, и именно этот метод демонстрирует наилучшие результаты среди всех рассмотренных. Существенный прирост качества по сравнению с baseline показывает, что различия между человеческими и AI-текстами проявляются не только на уровне слов, но и на уровне контекста и семантики.
Дополнительно в проекте исследуются большие языковые модели в режиме zero-shot. Модели GPT и DeepSeek используются без дообучения и без предоставления примеров, исключительно на основе текстовой инструкции. Такой сценарий хорошо отражает реальные условия, когда размеченные данные отсутствуют. Результаты zero-shot моделей ожидаемо уступают fine-tuned RuBERT, однако остаются устойчивыми и осмысленными. При этом GPT показывает более высокое качество по сравнению с DeepSeek.

В целом результаты проекта демонстрируют понятную иерархию методов. Классический baseline задаёт разумный нижний уровень качества, дообученная трансформерная модель RuBERT обеспечивает наилучшие результаты, а zero-shot большие языковые модели занимают промежуточное положение и могут быть полезны в сценариях быстрого применения без обучения. Таким образом, при наличии размеченных данных наиболее эффективным решением остаются fine-tuned трансформеры.
В качестве направлений для дальнейшей работы можно рассмотреть более тонкую настройку RuBERT за счёт подбора гиперпараметров, таких как скорость обучения, размер батча и количество эпох. Эти параметры не исследовались подробно в рамках проекта из-за ограниченности вычислительных ресурсов, однако их оптимизация потенциально может привести к дальнейшему росту качества. Также интерес представляет использование альтернативных русскоязычных трансформеров и исследование few-shot стратегий для больших языковых моделей.


P.s. Для ознакомления с более подробным анализом показателей метрик качества разных методов жду вас на защите презентации!
